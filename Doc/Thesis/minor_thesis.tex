% RMIT University School of CS&IT
% Minor thesis template
% S.M.M. (Saied) Tahaghoghi, 2004
\documentclass[11pt,twoside]{report}
\usepackage{a4wide,caption,epsfig,fancyheadings,natbib,url,multirow,makecell}

% Place the correct values here
%Set to the original submission date when submitted amended thesis
\newcommand{\SubmissionDate}{\today}
\newcommand{\student}{Bin Lu}
\newcommand{\supervisor}{Dr Jenny Zhang, Dr Amanda Kimpton, Dr Daryl D'Souza}
\newcommand{\topic}{Topic Modelling of Patient Opinion}
\newcommand{\school}{School of Computer Science and Information Technology}
\newcommand{\program}{Masters of Computer Science}
\newcommand{\institution}{Royal Melbourne Institute of Technology}

% Use the remark command to highlight text for discussion
\newcommand{\remark}[1]{{\bf \em [\marginpar{$\Leftarrow$}#1]}}

\renewcommand{\leftmark}{\student}
\renewcommand{\rightmark}{\topic}
%\setlength{\headrulewidth}{0pt}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1.5ex plus 0.3ex}

% This is the line spacing - set to 2 for draft submission to
% supervisor, 1.3 for the final submission
\renewcommand{\baselinestretch}{2.00}

\renewcommand{\captionfont}{\it}
\raggedbottom

%For Natbib Author, year citation format
% - the opening bracket symbol, default = (
% - the closing bracket symbol, default = )
% - the punctuation between multiple citations, default = ;
% - the letter n for numerical style, or s for numerical superscript
%   style, any other letter for author year, default = author year;
% - the punctuation that comes between the author names and the year
% - the punctuation that comes between years or numbers when common author lists are suppressed (default = ,);
\bibpunct{[}{]}{;}{a}{,}{;}


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{{\Large\bf \topic}}
\author{
A minor thesis submitted in partial fulfilment of the requirements for the degree of
\\\program\\*[10mm]
%\epsfig{figure=Figs/rmit-coa.epsf,width=5cm}
\\\student
\\\school
\\Science, Engineering, and Technology Portfolio,
\\\institution
\\Melbourne, Victoria, Australia
}
\maketitle
\thispagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Declaration}

This thesis contains work that has not been submitted previously, in
whole or in part, for any other academic award and is solely my
original research, except where acknowledged.

This work has been carried out since TODO:MONTH TODO:YEAR, under the
supervision of {\supervisor}.

\paragraph{}
\vspace{5cm}\noindent \\\student \\
\school\\
\institution\\
\SubmissionDate

\pagenumbering{roman}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Acknowledgements}

TODO:THANKS!

\tableofcontents
\listoffigures
\listoftables

\pagenumbering{arabic}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}



Publicly available opinions and service feedback provide valuable informations for decision making for both service providers and consumers. With the help of websites, blogs, forums and social networks, it is never been so easy to express opinions and leave feedback. Analysing the opinions becomes a challenge, not just because of the quantity of the data, most opinion from general users are free form text. The massive quantity of the data won’t be effectively used until there is a systematically approach of analysing and summarizing. Many techniques have been proposed to solve this problem. MDK-LDA model proposed by Chen(\cite{ref24}) , the method extends the Latent Dirichlet Allocation(\cite{ref25}), the later one becoming the standard method in topic modelling and been extended in variety ways. The basic idea of LDA is treat each document in a collection as a vector of word count, each document is represented as a probability distribution over a number of topics, while each topic is represented as a probability distribution over a number of words. MDK-LDA introduces a new latent variable s in LDA to model s-sets. Each document is an admixture of latent topics while each topic is a probability distribution over s-sets. Another approach is Aspect-based Summarization(\cite{ref11}), it is usually composed of three main tasks: aspect identification, sentiment classification, and aspect rating. Generally this model is used to analysing product review, it is designed to effectively retrieve features and sentiment for products.

Most previous studies focus on analysing product reviews. We are interested to discover some model that suite service reviews. More specifically, reviews relate to healthcare. Study shows the effective governance is increasingly recognized as pivotal to improvements in healthcare quality(\cite{ref6}), moreover current issue of effectiveness of the authority is affected by insufficient resource and inadequate information received(\cite{ref5}).
The object we are going to study is www.patientopinion.org.au, it is a publicly available healthcare forum. It allows user to post their own healthcare related story, the stories are not restricted from patient, it can also from hospital workers, nurses or doctors. The story can be positive or negative or a bit from both side. Although the story body is free form text, user still has to follow a certain template while submit the story.

\begin{figure}[tp]
    \begin{center}
    \epsfig{figure=Figs/story_sample.jpg,width=16.7cm}
    \caption
    [Patient Opinion Story Sample]
    {
    Patient Opinion Story Sample
    \label{Figure1}
    }
    \end{center}
\end{figure}

\begin{figure}[h]
    \begin{center}
    \epsfig{figure=Figs/story_sample_source1,width=16.7cm}
    \caption
    [Patient Opinion Story Sample Source 1]
    {
    Patient Opinion Story Sample Source 1
    \label{Figure2}
    }
    \end{center}
\end{figure}

\begin{figure}[h]
    \begin{center}
    \epsfig{figure=Figs/story_sample_source2,width=10.7cm}
    \caption
    [Patient Opinion Story Sample Source 2]
    {
    Patient Opinion Story Sample Source 2
    \label{Figure3}
    }
    \end{center}
\end{figure}

Due to the unique characteristic of the data from ‘Patient Opinion’, the existing models of topic modelling may not give the best result, on other hand LDA has been approved a very effective  model, and been used as a based model in many topic modelling studies. We choose LDA as our base model, and incorporate unique feature in ‘Patient Opinion’, specifically the section of ‘What’s Good’ and ‘What could be improved’. These two sections are filled in by user while submitting the story, the template is provided by the website. Generally this will be the main topic or features user want to give feedback about in the story. And we assume user labelled story 100\% accurate. The question we aim to answer in this thesis:
\begin{itemize}
\item How to use user specified features to improve the performance and accuracy in topic modelling.
\item What is the distribution of topics over locations (State level).
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Related Works}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{LDA}
Also known as Latent Dirichlet Allocation or discrete PCA is a Bayesian graphical model for text document collections represented by bags-of-words (\cite{ref26}, \cite{ref25}, \cite{ref30}, \cite{ref31}). The model allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. Generally, only a small number of words have high likelihood in each topic and each document only presents certain number of topics. Following is the equation of collapsed Gibbs sampling:
\begin{equation}
p(z_{id}=t\mid x_{id}=w,Z^{\neg id}) \alpha
\end{equation}
\begin{equation}
\frac{N_{wt}^{\neg id} + \beta}{\sum_{w}N_{wt}^{\neg id} + W\beta} \frac{N_{wt}^{\neg id} + \alpha}{\sum_{w}N_{wt}^{\neg id} + T\alpha}
\end{equation}
% ~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{MDK-LDA}
As mentioned before, LDA is a powerful topic modeling framework, however recent studies found that these unsupervised models may not produce topics that conform to the user's existing knowledge(\cite{ref24}). Chen et al (\cite{ref24}) proposed a novel knowledge-based model, called MDK-LDA, which is capable of using prior knowledge from multiple domains to help topic modeling in the new domain. A new latent variable 's' is added to model the s-set, each document represent admixture of latent topics while each topic is a probability distribution over s-set. MDK-LDA uses s-set to distinguish topics in multiple senses. For example the world light can be represented by two s-set: {light, heavy, weight} and {light, bright, luminance}, if light co-occurs with bright or luminance it will be assigned to s-set {light, bright, luminance}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{The Approach}

Although LDA provides a powerful framework for extracting latent topics in text document, but sometimes learned topics are lists of words that do not convey much useful information (\cite{ref26}). Some extrinsic evaluation has been used to demonstrate the effectiveness of the learned topic in the application domain, but standardly, no attempt has been made to perform intrinsic evaluation of the topics themselves, either qualitatively or quantitatively (\cite{ref27}). To solve the problem, base LDA model had been extended either by incorporating human judgement in to the model-learning framework or creating a computational proxy that simulates human judgements (\cite{ref28}), for example the MDK-LDA model (\cite{ref24}) we introduced in section 2.
Due to the unique characteristic of the data of Patient Opinion, we use user input to simulate human judgement, hence to produce a better quality topic modelling result.

% ~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Description of Data}

Data from Patient Opinion contains many informations, however we only interested in few parts of them in our project Figure 1: 1) The title of the story, it’s the summary of story by the user. 2) The author role and time of the post, the role could be the patient, patient’s relative, carer or doctor. 3) The more about section is from website moderator, it inserts relevant tags to the story. 4) \& 5) are the most important fields to our project, these field are inserted by the user, the fields indicate what user thinks the story is about, and we use these fields to simulate user judgement in topic modelling….

% ~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Preprocessing of Data}

Everything been converted to lower-case, collect all unique words in user specified field. This collection is used to filter out the words in each topic that generated by LDA. A list of related document ID to each word also collected, see Figure3.1.

\begin{figure}[tp]
    \begin{center}
    \epsfig{figure=Figs/data_sample1.jpg,width=8cm}
    \caption
    [Patient Opinion Story Sample]
    {
    Patient Opinion Story Sample
    \label{Figure4}
    }
    \end{center}
\end{figure}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Using user input to improve topic modelling result}

Topics learned from LDA sometimes don’t convey much useful information, sometime it is caused by overfeeding the result set, for example it will include top 20 words for each topic (based on the settings, the total number in each topic can be configured), some words may not make any sense in current topic but statistically significant to the topic. Our goal  is try to use user input to reduce the noise while retaining as much information as possible to describe or label the topic. The generative process is given as follows: 
\begin{enumerate}
\item Collect unique words from user specified field as \textit{S} set.
\item Generate a set of topics \textit{T} with LDA model.
\item Calculate result set \textit{R} as: for each topic $t\in\{1,...,T\}, r_n = t_n \cap S$
%\item Calculate tr-idf for each term
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experiments and Result}

We collected all 624 stories from Patient Opinion by August 2014. The count of unique user specified term is 659. 100 topics are generated using Mallet \footnote{http://mallet.cs.umass.edu/} with setting of optimize interval equals to 20. Table4.1 shows top 12 topics, it is ranked by the number of terms in original topic that matches the user specified terms
\begin{table}[ht]
\tiny
\caption{Top 12 topics}
\centering
\begin{tabular}{|c|c|}
\hline\hline
Original & Filtered\\
\hline
\makecell{program healthy kate lifestyle sessions eat meet programme\\
	 included organised held healthier encouraging learnt foods\\
	 beneficial learning relationship handle} & {program kate lifestyle meet included learnt learning relationship} \\
\hline

\makecell{gp local recently records government copy prescription\\
	 paper multiple tasmania gps referring avail beginning calls\\
	  surprised cairns super shared } & {gp local records government prescription paper gps cairns}\\
\hline

\makecell{physio gp mri injury follow shoulder xray week asked\\
	 hospital discussed full physiotherapist neck stand \\
	 complaining neurologist princess forte} & {physio gp mri xray hospital full physiotherapist neck}\\
\hline

\makecell{call waiting phone told back called list unit\\
	 rang ring explain apparently assumed clerk calling\\
	 noticed mcewin lyell requested} & {call waiting phone back list unit clerk calling}\\
\hline
  
\makecell{father bed family care appears staff time\\
	 attending difficult dad speak comfort unit incident\\
	 law visitor awake gosford palliative} & {bed family care staff time attending unit palliative}\\
\hline
	
\makecell{time advised team contact causing consultant tumour\\
	 professional manner independent safe stressful arrival\\
	 note closed usual considerate empathetic seizures} & \makecell{time team contact consultant professional manner\\ independent empathetic}\\
\hline

\makecell{looked experience er bad partner full approach worry\\
	 give free skills male chronic terrible running provider\\
	  building drive welcomed} & {looked experience er partner full approach skills male building}\\
\hline

\makecell{night stay thing major hospital admission support\\
	 suggested accommodation fully sydney unable relatives\\
	 sleep developed tuesday staff added environment} & \makecell{night stay hospital admission accommodation relatives\\ sleep staff environment}\\
\hline

\makecell{waiting wait hours room hour area waited reception\\
	 number temperature hurt remember panadol minutes geelong\\
	 sunday impressed time er} & {waiting wait hours room area reception number time er}\\
\hline

\makecell{child issues jean aboriginal helped understanding\\ 
	knowledge school minds behaviour hay mighty woods anger\\ 
	louise clinician strategies interaction love} & \makecell{child jean aboriginal understanding knowledge\\ 
	school minds behaviour woods strategies}\\
\hline

\makecell{public brisbane system live mater hospital pa\\ 
	run booking advise toowoomba meds qld health expect\\ 
	west lift weekend weak} & \makecell{public brisbane system hospital run booking meds\\ health west lift}\\
\hline

\makecell{health community sarah local support primary\\ 
	medicare rural group libby people murrumbidgee provide\\ 
	part clients topics art groups guest} & \makecell{health community sarah local primary medicare rural\\ group people murrumbidgee clients guest}\\
\hline
\end{tabular}
\label{table:Sample of top 20 original and filtered topics}
\end{table}

The total number of terms in the result set \textit{R} is 527, compare to 2000 in original \textit{T} set.
Table4.1 shows the sum of composition for each term in the topic in set  \textit{R} and \textit{T}
\begin{table}[ht]
\caption{Sum of Composition}
\centering
\begin{tabular}{c c c}
\hline\hline
Doc Index & Original Composition & Filtered Composition\\
\hline
1 & 3.920362 & 3.382284\\
2 & 3.742091 & 3.275150\\
3 & 4.396231 & 3.930039\\
4 & 4.275353 & 3.603821\\
5 & 4.569670 & 4.444751\\
6 & 3.153133 & 2.775077\\
7 & 3.368214 & 2.622281\\
8 & 4.541646 & 4.018145\\
9 & 5.399709 & 5.194911\\
10 & 4.498450 & 3.711763\\
11 & 4.255079 & 4.101976\\
12 & 6.755018 & 6.489172\\
\hline
\end{tabular}
\label{table:Topic Composition}
\end{table}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Topic Coherence Evaluation}
Apart from quantitative and qualitative evaluation as above, evaluating topic coherence is a component of the larger question of what are good topics, what characteristics of a document collection make it more amenable to to topic modelling, and how can the potential of topic modellling be harnessed for human consumption (\cite{ref27}). The topic coherence is measured as
\begin{equation}
score(\omega_i, \omega_j) = log\frac{D(\omega_i, \omega_j) + 1}{D(\omega_i}
\end{equation}
\begin{table}[ht]
\caption{Sum of Composition}
\centering
\begin{tabular}{c c c}
\hline\hline
Doc Index & Original Topic Coherence & Filtered Topic Coherence\\
\hline
1 & 0 & -25.093878\\
2 & 0 & -32.617172\\
3 & 0 & -27.143555\\
4 & 0 & -26.677283\\
5 & 0 & -28.104525\\
6 & 0 & -31.384130\\
7 & 0 & -38.548792\\
8 & 0 & -41.019321\\
9 & 0 & -31.220371\\
10 & 0 & -45.495693\\
11 & 0 & -52.946951\\
12 & 0 & -57.020165\\
\hline
\end{tabular}
\label{table:Topic Coherence}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion and Future Work}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix
\chapter{Testbed Configuration}

\bibliographystyle{abbrvnat}
\bibliography{Bib/strings,Bib/main}
\end{document}
\end{document}
